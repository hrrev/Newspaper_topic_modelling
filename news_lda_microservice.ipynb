{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing some required libraries\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "from newsplease import NewsPlease\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_lda(date_str,k):\n",
    "    \n",
    "    #This is my nytimes developer API key required to make the requests.\n",
    "    API_KEY=\"3EhyoUDWeGwW0vTGCY931FOgXOHCGBAj\"\n",
    "    \n",
    "    date_trimmed=date_trimmed=date_str[6:]+date_str[0:2]+date_str[3:5]\n",
    "    DATE=date_trimmed\n",
    "    \n",
    "    #components of url for api query\n",
    "    PREFIX=\"http://api.nytimes.com/svc/search/v2/articlesearch.json?begin_date=\"\n",
    "    CENTER=\"&end_date=\"\n",
    "    SUFFIX=\"&api-key=\"\n",
    "    \n",
    "    #generating the url\n",
    "    url=PREFIX+date_trimmed+CENTER+date_trimmed+SUFFIX+API_KEY\n",
    "    print(url)\n",
    "    \n",
    "    \n",
    "    #getting the json file by making request to the servar\n",
    "    response_json=requests.get(url).json()\n",
    "    print(response_json.keys())\n",
    "    \n",
    "    \n",
    "    #finding total number of documents\n",
    "    num_docs=response_json['response']['meta']['hits']\n",
    "    print(num_docs)\n",
    "\n",
    "    #adding the documents on first page in a newly created list of all document\n",
    "    docs=response_json['response']['docs']\n",
    "    \n",
    "    \n",
    "    #since each page contains 10 queries\n",
    "    if num_docs%10 is 0:\n",
    "        adjuster=1\n",
    "    else:\n",
    "        adjuster=0\n",
    "\n",
    "    total_pages = int(num_docs/10)+1-adjuster\n",
    "\n",
    "\n",
    "    # In[33]:\n",
    "\n",
    "\n",
    "    for page in range(1,total_pages):\n",
    "        #creating the url, basically page arguement allows us to get different documents\n",
    "        #page=0 gives first 10, page=1 gives next 10 and so on\n",
    "        url=PREFIX+DATE+CENTER+DATE+\"&page=\"+str(page)+SUFFIX+API_KEY\n",
    "        response_json=requests.get(url).json()\n",
    "\n",
    "        #Okay so nytimes allows only 10 queries in a minute(and only 4000 in a day)\n",
    "        #so let's wait a minute before making the same query again\n",
    "        if not 'response' in response_json.keys():\n",
    "            print(\"Waiting for 1 minute before making another request\")\n",
    "            time.sleep(60)\n",
    "            response_json=requests.get(url).json()        \n",
    "\n",
    "        #adding these documents to our list as well\n",
    "        new_docs = response_json['response']['docs']\n",
    "        docs.extend(new_docs)\n",
    "        \n",
    "    \n",
    "    #making the list of web urls    \n",
    "        web_urls = []\n",
    "\n",
    "        for doc in docs:\n",
    "            web_urls.append(doc['web_url'])\n",
    "            \n",
    "\n",
    "    #adding articles to the list\n",
    "    articles=[]\n",
    "\n",
    "    for i in range(len(docs)):\n",
    "        try:\n",
    "            article=NewsPlease.from_url(web_urls[i])\n",
    "            articles.append(article)\n",
    "            print(\"Success in article {}\".format(i))\n",
    "        except:\n",
    "            print(\"Encountered HTTPError in one of the pages moving on\")\n",
    "            print(web_urls[i])\n",
    "    \n",
    "    #checking if articles files exists from previous run\n",
    "    filenames = os.listdir()\n",
    "    if \"articles.json\" in filenames:\n",
    "        !rm \"articles.json\"\n",
    "    \n",
    "    articles_in_dic_format = [article.get_dict() for article in articles]\n",
    "    \n",
    "    \n",
    "    #taking the relevant three sections from each article\n",
    "    simplified_articles = [(str(article['description']) + str(article['text']) + str(article['title']) ) for article in articles_in_dic_format]\n",
    "    \n",
    "    #saving this for future se\n",
    "    with open('articles.json','w') as file:\n",
    "        json.dump(simplified_articles,file)\n",
    "        \n",
    "    with open('articles.json','r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "    #now the lda part\n",
    "    \n",
    "    def lemmatize_stemming(text):\n",
    "        return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    def preprocess(text):\n",
    "        result = []\n",
    "        for token in gensim.utils.simple_preprocess(text):\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "                result.append(lemmatize_stemming(token))\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    #processing each doc and adding it to list of processed_docs\n",
    "    processed_docs = [preprocess(doc) for doc in data]\n",
    "    \n",
    "    \n",
    "    #creating a dictionary maping each word to id\n",
    "    #note that this is very small data\n",
    "    #else we should have used MapReduce\n",
    "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "            \n",
    "            \n",
    "    #right now dont feel I have use of keep_n parameter as number of docs is very low\n",
    "    #not keeping words that appear in less than 5 documens\n",
    "    #not keeping words appearing in more than 50 percent documents\n",
    "    #maybe I would have set no_above lower if we had a larger dataset\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    \n",
    "    \n",
    "    #document representation in bag of words format\n",
    "    #basically each doc is now just words and their frequency without any importance to position\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "    \n",
    "    \n",
    "    #reqiire these for tfidf model\n",
    "    from gensim import corpora, models\n",
    "\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "    from pprint import pprint\n",
    "        \n",
    "    #training LDA model based on BOW\n",
    "    lda_model_bow = gensim.models.LdaMulticore(bow_corpus, num_topics=k, id2word=dictionary,batch=False, passes=10, workers=None, iterations=1000)\n",
    "    \n",
    "    #getting visualization tool ready\n",
    "    vis_lda_bow = pyLDAvis.gensim.prepare(lda_model_bow, bow_corpus, dictionary)\n",
    "    \n",
    "    pyLDAvis.save_html(vis_lda_bow, '/newvolume/data_transfer/nytimes/templates/lda2.html')\n",
    "    pyLDAvis.save_html(vis_lda_bow, '/newvolume/data_transfer/nytimes/templates/lda.html')\n",
    "\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "203.110.242.24 - - [24/Mar/2019 12:38:37] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-24-2004\n",
      "5\n",
      "http://api.nytimes.com/svc/search/v2/articlesearch.json?begin_date=20040324&end_date=20040324&api-key=3EhyoUDWeGwW0vTGCY931FOgXOHCGBAj\n",
      "dict_keys(['status', 'copyright', 'response'])\n",
      "251\n",
      "Waiting for 1 minute before making another request\n",
      "Waiting for 1 minute before making another request\n",
      "Success in article 0\n",
      "Success in article 1\n",
      "Success in article 2\n",
      "Success in article 3\n",
      "Success in article 4\n",
      "Success in article 5\n",
      "Success in article 6\n",
      "Success in article 7\n",
      "Success in article 8\n",
      "Success in article 9\n",
      "Success in article 10\n",
      "Success in article 11\n",
      "Success in article 12\n",
      "Success in article 13\n",
      "Success in article 14\n",
      "Success in article 15\n",
      "Success in article 16\n",
      "Success in article 17\n",
      "Success in article 18\n",
      "Success in article 19\n",
      "Success in article 20\n",
      "Success in article 21\n",
      "Success in article 22\n",
      "Success in article 23\n",
      "Success in article 24\n",
      "Success in article 25\n",
      "Success in article 26\n",
      "Success in article 27\n",
      "Success in article 28\n",
      "Success in article 29\n",
      "Success in article 30\n",
      "Success in article 31\n",
      "Success in article 32\n",
      "Success in article 33\n",
      "Success in article 34\n",
      "Success in article 35\n",
      "Success in article 36\n",
      "Success in article 37\n",
      "Success in article 38\n",
      "Success in article 39\n",
      "Success in article 40\n",
      "Success in article 41\n",
      "Success in article 42\n",
      "Encountered HTTPError in one of the pages moving on\n",
      "https://www.nytimes.com/2004/03/24/sports/going-far.html\n",
      "Success in article 44\n",
      "Success in article 45\n",
      "Success in article 46\n",
      "Success in article 47\n",
      "Success in article 48\n",
      "Success in article 49\n",
      "Success in article 50\n",
      "Success in article 51\n",
      "Success in article 52\n",
      "Success in article 53\n",
      "Success in article 54\n",
      "Success in article 55\n",
      "Success in article 56\n",
      "Success in article 57\n",
      "Success in article 58\n",
      "Success in article 59\n",
      "Success in article 60\n",
      "Success in article 61\n",
      "Encountered HTTPError in one of the pages moving on\n",
      "https://cooking.nytimes.com/recipes/9386-halvah-honey-sauce\n",
      "Success in article 63\n",
      "Success in article 64\n",
      "Success in article 65\n",
      "Success in article 66\n",
      "Success in article 67\n",
      "Success in article 68\n",
      "Success in article 69\n",
      "Success in article 70\n",
      "Success in article 71\n",
      "Success in article 72\n",
      "Success in article 73\n",
      "Success in article 74\n",
      "Success in article 75\n",
      "Success in article 76\n",
      "Success in article 77\n",
      "Success in article 78\n",
      "Success in article 79\n",
      "Success in article 80\n",
      "Success in article 81\n",
      "Success in article 82\n",
      "Success in article 83\n",
      "Success in article 84\n",
      "Success in article 85\n",
      "Success in article 86\n",
      "Success in article 87\n",
      "Success in article 88\n",
      "Success in article 89\n",
      "Success in article 90\n",
      "Success in article 91\n",
      "Success in article 92\n",
      "Success in article 93\n",
      "Success in article 94\n",
      "Success in article 95\n",
      "Success in article 96\n",
      "Success in article 97\n",
      "Success in article 98\n",
      "Success in article 99\n",
      "Success in article 100\n",
      "Success in article 101\n",
      "Success in article 102\n",
      "Success in article 103\n",
      "Success in article 104\n",
      "Success in article 105\n",
      "Success in article 106\n",
      "Success in article 107\n",
      "Success in article 108\n",
      "Success in article 109\n",
      "Success in article 110\n",
      "Success in article 111\n",
      "Success in article 112\n",
      "Success in article 113\n",
      "Success in article 114\n",
      "Success in article 115\n",
      "Success in article 116\n",
      "Success in article 117\n",
      "Success in article 118\n",
      "Success in article 119\n",
      "Success in article 120\n",
      "Success in article 121\n",
      "Success in article 122\n",
      "Success in article 123\n",
      "Success in article 124\n",
      "Success in article 125\n",
      "Success in article 126\n",
      "Success in article 127\n",
      "Success in article 128\n",
      "Success in article 129\n",
      "Success in article 130\n",
      "Success in article 131\n",
      "Success in article 132\n",
      "Success in article 133\n",
      "Success in article 134\n",
      "Success in article 135\n",
      "Success in article 136\n",
      "Success in article 137\n",
      "Success in article 138\n",
      "Success in article 139\n",
      "Success in article 140\n",
      "Success in article 141\n",
      "Success in article 142\n",
      "Success in article 143\n",
      "Success in article 144\n",
      "Success in article 145\n",
      "Success in article 146\n",
      "Success in article 147\n",
      "Success in article 148\n",
      "Success in article 149\n",
      "Success in article 150\n",
      "Success in article 151\n",
      "Success in article 152\n",
      "Success in article 153\n",
      "Success in article 154\n",
      "Success in article 155\n",
      "Success in article 156\n",
      "Success in article 157\n",
      "Success in article 158\n",
      "Success in article 159\n",
      "Success in article 160\n",
      "Success in article 161\n",
      "Success in article 162\n",
      "Success in article 163\n",
      "Success in article 164\n",
      "Success in article 165\n",
      "Success in article 166\n",
      "Success in article 167\n",
      "Success in article 168\n",
      "Success in article 169\n",
      "Success in article 170\n",
      "Success in article 171\n",
      "Success in article 172\n",
      "Success in article 173\n",
      "Success in article 174\n",
      "Success in article 175\n",
      "Success in article 176\n",
      "Success in article 177\n",
      "Success in article 178\n",
      "Success in article 179\n",
      "Success in article 180\n",
      "Success in article 181\n",
      "Success in article 182\n",
      "Success in article 183\n",
      "Success in article 184\n",
      "Success in article 185\n",
      "Success in article 186\n",
      "Success in article 187\n",
      "Success in article 188\n",
      "Success in article 189\n",
      "Success in article 190\n",
      "Success in article 191\n",
      "Success in article 192\n",
      "Success in article 193\n",
      "Success in article 194\n",
      "Success in article 195\n",
      "Success in article 196\n",
      "Success in article 197\n",
      "Success in article 198\n",
      "Success in article 199\n",
      "Success in article 200\n",
      "Success in article 201\n",
      "Success in article 202\n",
      "Success in article 203\n",
      "Success in article 204\n",
      "Success in article 205\n",
      "Success in article 206\n",
      "Success in article 207\n",
      "Success in article 208\n",
      "Success in article 209\n",
      "Success in article 210\n",
      "Success in article 211\n",
      "Success in article 212\n",
      "Success in article 213\n",
      "Success in article 214\n",
      "Success in article 215\n",
      "Success in article 216\n",
      "Success in article 217\n",
      "Success in article 218\n",
      "Success in article 219\n",
      "Success in article 220\n",
      "Success in article 221\n",
      "Success in article 222\n",
      "Success in article 223\n",
      "Success in article 224\n",
      "Success in article 225\n",
      "Success in article 226\n",
      "Encountered HTTPError in one of the pages moving on\n",
      "https://www.nytimes.com/2004/03/24/us/a-mountain-hike-turns-deadly.html\n",
      "Success in article 228\n",
      "Success in article 229\n",
      "Success in article 230\n",
      "Success in article 231\n",
      "Success in article 232\n",
      "Success in article 233\n",
      "Success in article 234\n",
      "Success in article 235\n",
      "Success in article 236\n",
      "Success in article 237\n",
      "Success in article 238\n",
      "Success in article 239\n",
      "Success in article 240\n",
      "Success in article 241\n",
      "Success in article 242\n",
      "Success in article 243\n",
      "Success in article 244\n",
      "Success in article 245\n",
      "Success in article 246\n",
      "Success in article 247\n",
      "Success in article 248\n",
      "Success in article 249\n",
      "Success in article 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203.110.242.24 - - [24/Mar/2019 12:53:03] \"GET /input?date=03-24-2004&num_topics=5 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, url_for, request, jsonify\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def hello_world():\n",
    "   return render_template(\"headline_correcter.html\")\n",
    "\n",
    "\n",
    "@app.route('/input',methods = ['GET'])\n",
    "def input_taker():\n",
    "    if request.method == 'GET':\n",
    "        date_str = request.args.get('date')\n",
    "        num_topics = request.args.get('num_topics')\n",
    "        print(date_str)\n",
    "        print(num_topics)\n",
    "        news_lda(date_str,num_topics)\n",
    "        \n",
    "    return render_template(\"lda.html\")\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "   app.run(host= '0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
